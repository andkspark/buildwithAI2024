{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Start_RAG_with_Gemini_and_Langchain\n",
        "해당 노트는 Build with AI in Songdo 2024의 진행을 위하여 제작되었습니다.  \n",
        "제작 : 박광석(모두의연구소, https://www.linkedin.com/in/andkspark)\n",
        "  \n",
        "해당 노트는 Langchain으로 RAG를 구현하기 위해 필요한  \n",
        "각 컴포넌트인 Document Loaders, Text splitters, Text embeddings, Vectorstores, Retriever를 다룹니다    \n",
        "참고 :\n",
        "https://python.langchain.com/docs/get_started/introduction  \n",
        "https://python.langchain.com/docs/integrations/llms/google_ai/  \n",
        "YouTube <모두의AI> , <테디노트>   \n",
        "인프런 <모두를 위한 대규모 언어 모델 LLM(Large Language Model) Part 2 - 랭체인(LangChain)으로 나만의 ChatGPT 만들기>\n",
        "\n"
      ],
      "metadata": {
        "id": "HFMBYK2SwI68"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 0 : 설치와 준비  \n",
        "Langchain 설치 및 Gemini API 키를 등록하도록 합니다.  "
      ],
      "metadata": {
        "id": "drDsT9tbxZZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDlkZu50yHxQ",
        "outputId": "6a0dcb3a-0a44-438d-f32d-963c89f6f80a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "YOUR_API_KEY = 'AIzaSyCZ9YYpH1LRAd2i_KPnlsoOy3C4hB_2KYE'"
      ],
      "metadata": {
        "id": "5QZZobfdyUYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_Q-g7IgwHGT"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['GOOGLE_API_KEY'] = YOUR_API_KEY"
      ],
      "metadata": {
        "id": "On8wrXDKwIWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#랭체인의 구글Api를 사용합니다\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "llm = ChatGoogleGenerativeAI(model = \"gemini-pro\", temperature=0.0)"
      ],
      "metadata": {
        "id": "P6wvjjbp0jMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pypdf pdf2image docx2txt pdfminer unstructured #의존성 모듈을 설치합니다"
      ],
      "metadata": {
        "id": "l3ixY6SKkkXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1 : Document Loaders 사용해보기  \n",
        "Document Loader는 PDF, 웹페이지, CSV 등 여러 종류의 문서를 text로 파싱하는 기능을 가지고 있습니다.  \n",
        "https://python.langchain.com/docs/modules/data_connection/document_loaders/  "
      ],
      "metadata": {
        "id": "boezOrKC4wEm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://it.chosun.com/news/articleView.html?idxno=2023092111831"
      ],
      "metadata": {
        "id": "x2uSFtWM8zam"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### PDFLoader 사용  \n",
        "읽고 싶은 pdf 파일을 드라이브에 올려주세요!    "
      ],
      "metadata": {
        "id": "X9PS0ysEpZao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(\"/content/Demian.pdf\")\n",
        "pages = loader.load_and_split()"
      ],
      "metadata": {
        "id": "XqlRblKtjXD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pages[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOmJL1JhkLcP",
        "outputId": "64c677da-82ed-4ba3-f1d0-7c8a729e7cf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='DEMIAN • \\nDownloaded from https://www.holybooks.com', metadata={'source': '/content/Demian.pdf', 'page': 0})"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pages[10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfeJptoHlIiA",
        "outputId": "8ff6ed85-dfce-416b-9ffb-60cb481e39d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content='TWO WOR.LDS \\nFinally, out of sheer nervousness, I began to talk. I \\ninvented a long story of robbery, in which I featured as \\nthe hero. One night in the comer by the mill a friend \\nand I ha.d stolen a whole sackful of apples, not just \\nordinary apples but pippins, golden pippins of the best \\nkind at that. I was taking refuge in my story from the \\ndangers of the moment and found no difficulty in invent\\xad\\ning and relating it. In order not to dry up too soon and \\nperhaps become involved in something worse, I gave full \\nrein to my narrative powers. One of us, I reported, had \\nalways stood guard while the other sat in the tree and \\nchucked the apples down, and the sack had got so heavy \\nthat in the end we had to open it and leave half behind, \\nbut we came back half an hour later and fetched them \\ntoo. \\nI hoped for some applause at the end of my story; I \\nhad warmed up to the narrative aJ: last, carried away by \\nmy own eloquence. The two smaller boys were silent, \\nwaiting, Lut Franz Kromer gave me a penetrating look \\nthrough his narrow,-1 eyes. \"Is that yarn true?\" he \\nasked in a menacing tone. \\n\"Yes,\" I said. \\n\"Really and truly?\" \\n\"Yes, really and truly,\" I asserted defiantly while I \\nchoked inwardly with fear. \\n\"Can you swear to it?\" \\nI was very afraid but I said \\'Yes\\' without hesitation. \\n\"Hand on your heart?\" \\n\"Hand on my heart,\" \\n\"Right then,\" he said and turned away. \\nI thought this was all very satisfactory and I was glad \\n15 \\nDownloaded from https://www.holybooks.com' metadata={'source': '/content/Demian.pdf', 'page': 10}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "깔끔한 출력을 위해, page_content키만 접근해보겠습니다."
      ],
      "metadata": {
        "id": "GNnUqhR9sTP9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(pages[10].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWkhs1SMsOkE",
        "outputId": "e6fb3f8f-8e75-4f2a-a770-1a20f03db3ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TWO WOR.LDS \n",
            "Finally, out of sheer nervousness, I began to talk. I \n",
            "invented a long story of robbery, in which I featured as \n",
            "the hero. One night in the comer by the mill a friend \n",
            "and I ha.d stolen a whole sackful of apples, not just \n",
            "ordinary apples but pippins, golden pippins of the best \n",
            "kind at that. I was taking refuge in my story from the \n",
            "dangers of the moment and found no difficulty in invent­\n",
            "ing and relating it. In order not to dry up too soon and \n",
            "perhaps become involved in something worse, I gave full \n",
            "rein to my narrative powers. One of us, I reported, had \n",
            "always stood guard while the other sat in the tree and \n",
            "chucked the apples down, and the sack had got so heavy \n",
            "that in the end we had to open it and leave half behind, \n",
            "but we came back half an hour later and fetched them \n",
            "too. \n",
            "I hoped for some applause at the end of my story; I \n",
            "had warmed up to the narrative aJ: last, carried away by \n",
            "my own eloquence. The two smaller boys were silent, \n",
            "waiting, Lut Franz Kromer gave me a penetrating look \n",
            "through his narrow,-1 eyes. \"Is that yarn true?\" he \n",
            "asked in a menacing tone. \n",
            "\"Yes,\" I said. \n",
            "\"Really and truly?\" \n",
            "\"Yes, really and truly,\" I asserted defiantly while I \n",
            "choked inwardly with fear. \n",
            "\"Can you swear to it?\" \n",
            "I was very afraid but I said 'Yes' without hesitation. \n",
            "\"Hand on your heart?\" \n",
            "\"Hand on my heart,\" \n",
            "\"Right then,\" he said and turned away. \n",
            "I thought this was all very satisfactory and I was glad \n",
            "15 \n",
            "Downloaded from https://www.holybooks.com\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CSVLoader\n",
        "\n",
        "읽고 싶은 CSV 파일을 드라이브에 올려주세요!    "
      ],
      "metadata": {
        "id": "X4CmphsjlVe7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import CSVLoader\n",
        "\n",
        "loader = CSVLoader(\"/content/titanic.csv\")\n",
        "\n",
        "data = loader.load()"
      ],
      "metadata": {
        "id": "d3JlHDEfkRB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7W8rBr3ZkRFT",
        "outputId": "683412ab-5772-4cff-ec1c-4cdd36c2430e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='PassengerId: 1\\nSurvived: 0\\nPclass: 3\\nName: Braund, Mr. Owen Harris\\nSex: male\\nAge: 22\\nSibSp: 1\\nParch: 0\\nTicket: A/5 21171\\nFare: 7.25\\nCabin: \\nEmbarked: S', metadata={'source': '/content/titanic.csv', 'row': 0}),\n",
              " Document(page_content='PassengerId: 2\\nSurvived: 1\\nPclass: 1\\nName: Cumings, Mrs. John Bradley (Florence Briggs Thayer)\\nSex: female\\nAge: 38\\nSibSp: 1\\nParch: 0\\nTicket: PC 17599\\nFare: 71.2833\\nCabin: C85\\nEmbarked: C', metadata={'source': '/content/titanic.csv', 'row': 1}),\n",
              " Document(page_content='PassengerId: 3\\nSurvived: 1\\nPclass: 3\\nName: Heikkinen, Miss. Laina\\nSex: female\\nAge: 26\\nSibSp: 0\\nParch: 0\\nTicket: STON/O2. 3101282\\nFare: 7.925\\nCabin: \\nEmbarked: S', metadata={'source': '/content/titanic.csv', 'row': 2})]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 웹베이스로더  \n",
        "웹페이지를 파싱합니다"
      ],
      "metadata": {
        "id": "Ic7kJAZdljCe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import WebBaseLoader"
      ],
      "metadata": {
        "id": "RXhUGGr78fuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = WebBaseLoader(\"https://it.chosun.com/news/articleView.html?idxno=2023092111831\")\n",
        "documents = loader.load()\n",
        "\n",
        "# print(documents[0].page_content)"
      ],
      "metadata": {
        "id": "J8r1r7ofiJDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "주석을 풀고 수행하면, 해당 페이지의 모든 텍스트를 읽어옵니다.  \n",
        "    \n",
        "모든 형식을 텍스트로 잘 읽어왔습니다.  \n",
        "전처리 후 잘 사용할 수 있을 것 같습니다!"
      ],
      "metadata": {
        "id": "gyWvy7kpjRBt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step2 : TextSplitters 사용해보기  \n",
        "TextSplitter는 지정한 구분자, 혹은 다른 특정 기준을 특징으로 텍스트를 Chunk로 나누는 역할을 수행합니다.    \n",
        "LLM은 Splitters를 통해 분할된 여러 문서들을 입력받을 수 있으며, 이를 통해 토큰 길이의 제약을 극복해냅니다.  \n",
        "각각의 chunk들은 vectorstore에 1:1로 임베딩됩니다"
      ],
      "metadata": {
        "id": "u0Cq98LQrhdN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "id": "GWRl168fseiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CharacterTextSplitter는 구분자 1개를 기준으로 문장을 분할합니다  \n",
        "max_token을 초과하는 경우가 생깁니다.  \n",
        "  \n",
        "RecursiveCharacterTextSplitter는 줄바꿈, 마침표, 쉼표 등 구분자 여러개를 돌아가며 재귀적으로 분할합니다.  \n",
        "완전하지 않은 문장으로 분할하는 경우가 생깁니다.  "
      ],
      "metadata": {
        "id": "9nTaC1f6qet4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/state_of_the_union.txt\") as f:\n",
        "    text = f.read()"
      ],
      "metadata": {
        "id": "mbymWYyftnUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iFKsjtEGsqKG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#len은 어떤 기준으로 chunk size를 잴 것인가?의 기준이 되는 함수입니다.\n",
        "#chunk_overlap은 chunk의 앞뒤로 다른 chunk와 설정한 size까지 겹칠 수 있도록 설정하는 것입니다.\n",
        "text_splitter = CharacterTextSplitter(separator=\"\\n\\n\", chunk_size=1000, chunk_overlap=100, length_function = len,)\n",
        "chunks = text_splitter.split_text(text)"
      ],
      "metadata": {
        "id": "LdfFy8TttnRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chunk의 내용을 확인해보겠습니다"
      ],
      "metadata": {
        "id": "SrLtf9uhsC6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(chunks[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sa2Tl4Z2rvoN",
        "outputId": "0eebf7df-2e9b-4d8d-9135-a4a5d18a48ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and the Cabinet. Justices of the Supreme Court. My fellow Americans.  \n",
            "\n",
            "Last year COVID-19 kept us apart. This year we are finally together again. \n",
            "\n",
            "Tonight, we meet as Democrats Republicans and Independents. But most importantly as Americans. \n",
            "\n",
            "With a duty to one another to the American people to the Constitution. \n",
            "\n",
            "And with an unwavering resolve that freedom will always triumph over tyranny. \n",
            "\n",
            "Six days ago, Russia’s Vladimir Putin sought to shake the foundations of the free world thinking he could make it bend to his menacing ways. But he badly miscalculated. \n",
            "\n",
            "He thought he could roll into Ukraine and the world would roll over. Instead he met a wall of strength he never imagined. \n",
            "\n",
            "He met the Ukrainian people. \n",
            "\n",
            "From President Zelenskyy to every Ukrainian, their fearlessness, their courage, their determination, inspires the world.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "각 chunk의 길이를 확인해보겠습니다,"
      ],
      "metadata": {
        "id": "c54vuRYorulm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "length = []\n",
        "for chunk in chunks:\n",
        "    length.append(len(chunk))\n",
        "\n",
        "print(length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzu6paiZrNdQ",
        "outputId": "2987d236-a45e-40eb-bdd2-eed2c21c120d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[939, 995, 810, 962, 994, 883, 957, 952, 928, 915, 993, 702, 900, 950, 957, 958, 967, 996, 796, 866, 888, 966, 964, 977, 998, 948, 925, 924, 989, 965, 938, 936, 981, 965, 771, 982, 972, 977, 984, 999, 968, 801]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 토큰 단위로 텍스트 분할해보기  \n",
        "  \n",
        "LLM의 경우 토큰을 기준으로 자연어를 처리하기 때문에, 자연어의 form인 단어 길이는 서비스 개발에서 적합하지 않을 수 있습니다.  \n",
        "토큰 단위로 텍스트를 분할해보도록 하겠습니다!  \n"
      ],
      "metadata": {
        "id": "KAuuYWMwtQnh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIoqdNgntRMf",
        "outputId": "20185754-85a1-45d6-b9e8-43d3f3a49b96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
        "\n",
        "def tiktoken_len(text):\n",
        "    tokens = tokenizer.encode(\n",
        "        text\n",
        "    )\n",
        "    return len(tokens)"
      ],
      "metadata": {
        "id": "A1AGg0Kd-hDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tiktoken_length = []\n",
        "for chunk in chunks:\n",
        "    tiktoken_length.append(tiktoken_len(chunk))\n",
        "\n",
        "print(length)\n",
        "print(tiktoken_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeVf9LFl-0We",
        "outputId": "047d04c6-57f1-4f29-8815-6883414d35ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[939, 995, 810, 962, 994, 883, 957, 952, 928, 915, 993, 702, 900, 950, 957, 958, 967, 996, 796, 866, 888, 966, 964, 977, 998, 948, 925, 924, 989, 965, 938, 936, 981, 965, 771, 982, 972, 977, 984, 999, 968, 801]\n",
            "[197, 198, 163, 190, 203, 182, 195, 197, 206, 205, 218, 148, 188, 205, 216, 215, 209, 224, 176, 187, 201, 197, 201, 215, 222, 202, 203, 204, 229, 206, 184, 204, 197, 194, 156, 200, 194, 221, 203, 225, 209, 187]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "글자 수와 토큰 수의 차이를 확인할 수 있습니다 !"
      ],
      "metadata": {
        "id": "kuhWSpQn_bhM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step3 : TextEmbedding 사용해보기  \n",
        "컴퓨터가 텍스트를 이해할 수 있도록 벡터로 변환합니다.  \n",
        "변환된 벡터는 벡터스토어에 저장되거나, 기존의 다른 벡터와의 유사성을 계산할 수 있습니다.  \n",
        "변환은 대용량의 말뭉치로 사전훈련된 임베딩 모델을 통해 이루어지게 됩니다.  \n",
        "  \n",
        "Gemini pro의 임베딩 모델을 사용해보겠습니다!  \n",
        "https://ai.google.dev/docs/embeddings_guide?hl=ko"
      ],
      "metadata": {
        "id": "_9YtdfL5EhDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai"
      ],
      "metadata": {
        "id": "qQ7NM1NqGSY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "genai 라이브러리의 list_models 함수를 사용하여 사용 가능한 모델들의 목록을 가져옵니다."
      ],
      "metadata": {
        "id": "ZtVoy-CPG3o_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "genai.configure(api_key=YOUR_API_KEY)"
      ],
      "metadata": {
        "id": "4mmdbe8kGnWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model in genai.list_models():\n",
        "    if \"embedContent\" in model.supported_generation_methods:\n",
        "        print(model.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "ygXt2Uk6Fpf2",
        "outputId": "767011bc-e4cd-4df5-dbf2-a20ae23bc745"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/embedding-001\n",
            "models/text-embedding-004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "두 개의 임베딩 모델을 사용할 수 있습니다  \n",
        "\n",
        "https://github.com/google/generative-ai-docs/blob/main/examples/gemini/python/langchain/Gemini_LangChain_QA_Chroma_WebLoad.ipynb"
      ],
      "metadata": {
        "id": "ChRmKxfYHAUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "embedding_model = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")"
      ],
      "metadata": {
        "id": "1VB1lBquFpiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gemini embedding은 지역에 따라 사용이 제한됩니다.  \n",
        "주로 유럽권에서 제한되기 때문에, 다음 에러를 확인하신다면 Colab 파일의 서버 저장 위치를 확인 후, 다른 임베딩 모델로 변경해야합니다.  \n",
        "\n",
        "Error embedding content: 400 User location is not supported for the API use.\n"
      ],
      "metadata": {
        "id": "QNJFmhhwZCI5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl ipinfo.io"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRdFPMaSY1nF",
        "outputId": "2fc60798-1c73-4af0-8a47-beacc45cade5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"ip\": \"34.118.253.20\",\n",
            "  \"hostname\": \"20.253.118.34.bc.googleusercontent.com\",\n",
            "  \"city\": \"Washington\",\n",
            "  \"region\": \"Washington, D.C.\",\n",
            "  \"country\": \"US\",\n",
            "  \"loc\": \"38.8951,-77.0364\",\n",
            "  \"org\": \"AS396982 Google LLC\",\n",
            "  \"postal\": \"20004\",\n",
            "  \"timezone\": \"America/New_York\",\n",
            "  \"readme\": \"https://ipinfo.io/missingauth\"\n",
            "}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 400 User location is not supported for the API use 오류가 발생한다면, 이 블록을 대신 실행해주세요\n",
        "\n",
        "# ! pip install -q sentence_transformers\n",
        "\n",
        "#from langchain.embeddings import HuggingFaceEmbeddings\n",
        "#embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "id": "T4ocw0yxcg7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "embedding model 변수에 google의 임베딩모델 혹은 huggingface의 임베딩모델이 할당되었을 것입니다.  \n",
        "embed_documents 멤버 함수를 사용하여 새 문장을 변환해보겠습니다  "
      ],
      "metadata": {
        "id": "JmYNTUjheSFu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = embedding_model.embed_documents(\n",
        "    [\n",
        "        \"This is red apple.\",\n",
        "        \"This is yellow banana.\",\n",
        "        \"This is green lime.\",\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "2acBXTPIFpkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "임베딩으로 잘 변환되었는지 확인해보겠습니다  "
      ],
      "metadata": {
        "id": "eSfysI1PfWjA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(embeddings[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfqjyNfqfRUA",
        "outputId": "21e4f326-e125-4686-9f53-91e8b8f1d44f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.043598722666502, 0.046768173575401306, -0.02603815495967865, -0.0013704730663448572, 0.06055561825633049, 0.05017254129052162, 0.11730732768774033, -0.027721066027879715, 0.00927953515201807, 0.07751474529504776, 0.00151285610627383, -0.09486881643533707, 0.0018310209270566702, 0.010358014144003391, 0.022608978673815727, 0.043929990381002426, -0.01375606469810009, -0.02057924121618271, -0.03271389380097389, -0.02561490423977375, 0.04354718700051308, 0.08289311826229095, -0.05014246329665184, -0.04123269021511078, -0.05022476986050606, 0.040150634944438934, 0.057477813214063644, 0.012200258672237396, 0.028081489726901054, -0.06074453145265579, -0.0662989467382431, 0.02342129498720169, 0.048590973019599915, -0.015047339722514153, -0.020352855324745178, -0.0033349499572068453, 0.033707424998283386, -0.10650116950273514, 0.03428312763571739, 0.06269633769989014, 0.036975614726543427, 0.039933159947395325, 0.06028096750378609, -0.05295751616358757, -0.0250783059746027, 0.06646721065044403, 0.0071857585571706295, -0.030765414237976074, 0.0969342589378357, -0.12719327211380005, -0.022188343107700348, -0.09718192368745804, -0.06642643362283707, -0.04823513329029083, 0.021032657474279404, -0.0029274439439177513, 0.00874064490199089, -0.09547818452119827, 0.12179343402385712, 0.0524858720600605, 0.006675318349152803, -0.021719468757510185, 0.04861527308821678, 0.030012940987944603, 0.01756594330072403, -0.03230313956737518, -0.06621262431144714, -0.08468669652938843, 0.059202276170253754, -0.08233204483985901, 0.03709420561790466, 0.019973983988165855, 0.06621977686882019, 0.11005156487226486, -0.060954295098781586, 0.025802042335271835, 0.11528496444225311, 0.027877626940608025, -0.06134438514709473, 0.020671891048550606, -0.034381695091724396, -0.02531299740076065, 0.0020291341934353113, -0.04196614772081375, 0.05155527964234352, 0.04942721873521805, -0.025448942556977272, -0.02950139157474041, -0.023035597056150436, 0.0004184223071206361, -0.05497932434082031, 0.0938350111246109, 0.0624227412045002, -0.015318721532821655, -0.09398064017295837, -0.04870067164301872, -0.036455489695072174, -0.0518522784113884, -0.0689888522028923, 0.1252191960811615, 0.03966443985700607, 0.048000454902648926, 0.024541281163692474, -0.0205712728202343, 0.023431340232491493, -0.01767728477716446, 0.03246891498565674, 0.010828254744410515, 0.04916143789887428, 0.07566531002521515, 0.03547516465187073, -0.030778538435697556, -0.01666838862001896, 0.007814032956957817, -0.07591241598129272, -0.003166362177580595, 0.011857179924845695, 0.022899111732840538, -0.025209641084074974, 0.10389995574951172, 0.09573832154273987, -0.09201104938983917, -0.024041667580604553, -0.04868996888399124, -0.05682482570409775, -0.05736163258552551, 0.031908128410577774, -5.607881675641946e-33, 0.013070549815893173, 0.018413422629237175, 0.0623030886054039, -0.06526560336351395, 0.08400001376867294, -0.011253401637077332, -0.04227123036980629, 0.005747889168560505, 0.04904385283589363, -0.13502182066440582, -0.04398796707391739, -0.0240726750344038, -0.09521890431642532, 0.025402188301086426, -0.04639824852347374, 0.029313959181308746, -0.020988907665014267, 0.00653010094538331, -0.01911158859729767, 0.014863817021250725, -0.05060672014951706, 0.0323629193007946, 0.01995416358113289, -0.07332421094179153, -0.012918610125780106, -0.043864794075489044, -0.013943384401500225, -0.0724828839302063, 0.0650717094540596, 0.012206422165036201, 0.03891101852059364, 0.06709545850753784, 0.06602317839860916, 0.007380615919828415, -0.09268505871295929, -0.08214118331670761, 0.07366818189620972, -0.016693007200956345, -0.022771110758185387, 0.05775165185332298, 0.028694840148091316, -0.06437966227531433, -0.028294488787651062, 0.1231321394443512, -0.05285276100039482, 0.04324111342430115, 0.034838318824768066, 0.02143820933997631, 0.019175909459590912, -0.01945830136537552, -0.029185263440012932, -0.06057815998792648, -0.0044926912523806095, 0.024012301117181778, 0.017869025468826294, -0.04905286431312561, 0.039254654198884964, -0.003061216324567795, -0.03734201937913895, -0.034045133739709854, 0.007094585802406073, 0.022684063762426376, -0.005507878493517637, 0.07776731997728348, -0.058053337037563324, -0.025186801329255104, -0.07639069110155106, -0.03171537443995476, 0.1245943158864975, -0.09568876028060913, -0.026748038828372955, -0.03362410143017769, 0.11731275171041489, -0.03630451858043671, -0.030557522550225258, -0.08539465814828873, 0.04255729541182518, -0.05508055537939072, 0.013518090359866619, 0.016709573566913605, -0.00027409178437665105, -0.041185278445482254, 0.025379769504070282, 0.03415215015411377, -0.08997795730829239, 0.07486692070960999, -0.020154645666480064, -0.00978722982108593, -0.006027684081345797, -0.07746981829404831, -0.036503590643405914, 0.016304805874824524, -0.01682247780263424, -0.01012701541185379, -0.06889230012893677, 4.6927145078046704e-33, 0.01503659039735794, 0.040082190185785294, -0.002967685228213668, 0.04309399053454399, 0.035952817648649216, -0.034657321870326996, 0.03604678809642792, 0.03217717632651329, -0.12696200609207153, -0.016776785254478455, 0.014516769908368587, -0.025011999532580376, 0.025681860744953156, -0.02313397265970707, 0.09537620097398758, 0.07981400191783905, 0.06387999653816223, 0.0862148180603981, -0.06839600205421448, -0.0516679547727108, -0.036611076444387436, -0.04456941410899162, -0.0020024534314870834, -0.026174426078796387, 0.009862270206212997, 0.08978229761123657, -0.0027588633820414543, -0.06455159187316895, -0.01709073595702648, 0.00921740010380745, -0.011432524770498276, -0.04107163846492767, -0.0019135220209136605, -0.022122282534837723, -0.01679445058107376, -0.028083620592951775, 0.00824668351560831, -0.13644294440746307, -0.029575694352388382, 0.03814714401960373, 0.0035088532604277134, 0.021165242418646812, 0.0014108719769865274, 0.05808059871196747, -0.06766220182180405, -0.034935079514980316, 0.03900745138525963, 0.007043016608804464, 0.023391379043459892, 0.04320043325424194, 0.029103990644216537, -0.0011812421726062894, -0.01022060215473175, 0.0015845559537410736, -0.0315326564013958, 0.019301988184452057, -0.07357325404882431, 0.05402066931128502, -0.023723848164081573, 0.05682876333594322, 0.007070548832416534, -0.020576052367687225, -0.027106493711471558, 0.005085498560220003, 0.051553789526224136, 0.0877424031496048, 0.031233228743076324, 0.05005345866084099, 0.0056221215054392815, 0.03643800690770149, 0.026165377348661423, 0.01848478801548481, 0.01914350502192974, -0.055512797087430954, 0.003928625490516424, 0.08219939470291138, 0.05216445401310921, -0.09051482379436493, -0.04166053980588913, 0.011506898328661919, -0.03674980625510216, -0.02958637662231922, 0.007837066426873207, 0.05418427661061287, -0.04020974785089493, 0.05835774540901184, -0.009422139264643192, 0.029096176847815514, 0.04060022532939911, 0.04750075191259384, -0.023307442665100098, 0.03064293973147869, -0.006956077180802822, 0.046219319105148315, 0.007293033879250288, -1.4356476008003938e-08, 0.030280467122793198, -0.1382894366979599, -0.05402645841240883, 0.02307637222111225, 0.07051374018192291, 0.0682772621512413, 0.007171696051955223, -0.07849596440792084, 0.036607351154088974, -0.008095980621874332, -0.02992558665573597, 0.057947300374507904, -0.02410913072526455, 0.05675389990210533, 0.0006117270677350461, 0.013479048386216164, 0.023492828011512756, 0.0774397924542427, 0.00941239483654499, 0.06523973494768143, -0.07266988605260849, 0.01909252628684044, 0.014522841200232506, -0.050979066640138626, -0.02409023977816105, -0.0221791323274374, -0.06861184537410736, 0.1756846159696579, 0.012169972062110901, 0.019939592108130455, 0.006755813956260681, 0.04098706692457199, -0.04611463472247124, 0.0048309871926903725, 0.015200015157461166, 0.042150434106588364, 0.04578140750527382, 0.04471796378493309, -0.08846615999937057, -0.09298670291900635, 0.026469141244888306, 0.007480273488909006, -0.03505265340209007, 0.03581472113728523, -0.01843797042965889, -0.022256692871451378, -0.019436102360486984, 0.06065918132662773, -0.019779788330197334, -0.009569765068590641, 0.0050959461368620396, 0.04311720281839371, 0.015273607335984707, 0.03877182677388191, -0.0594613291323185, -0.1308325082063675, -0.043912436813116074, 0.01106246467679739, -0.05115905776619911, 0.06661159545183182, 0.03220139816403389, -0.03033023327589035, -0.007693484425544739, 0.0715286135673523]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(embeddings[1])"
      ],
      "metadata": {
        "id": "sHoo0oSdbPQ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78a59794-1c21-4580-8185-961c69a20d59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "384"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "새로운 쿼리를 넣어, 임베딩끼리 유사도를 계산해보겠습니다"
      ],
      "metadata": {
        "id": "q4Z93VhNnZWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "def cos_sim(A, B):\n",
        "  return dot(A, B)/(norm(A)*norm(B))"
      ],
      "metadata": {
        "id": "JdIPCKdegPoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = [\"this is red fruit\"]"
      ],
      "metadata": {
        "id": "OiF2Th_Wfbjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "e_query = embedding_model.embed_documents(query)\n",
        "print(cos_sim(embeddings[0], e_query[0]))\n",
        "print(cos_sim(embeddings[1], e_query[0]))\n",
        "print(cos_sim(embeddings[2], e_query[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Dw1abxlnH6x",
        "outputId": "d9da28c7-d96b-468f-e5ae-a5b35ce204a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7799129642398976\n",
            "0.6021169618560605\n",
            "0.5388709108177803\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "빨간 사과와 빨간 과일의 유사도가 많이 높게 나왔습니다!  \n",
        "  \n",
        "임베딩 모델은 사용 언어나 필요에 따라 다양하게 교체하여 사용할 수 있습니다.  \n",
        "해당 링크에서 여러 목록을 확인하실 수 있습니다.  \n",
        "https://python.langchain.com/docs/integrations/text_embedding/"
      ],
      "metadata": {
        "id": "jAQYsdGTniZ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step4 : VectorStore 사용해보기\n",
        "VectorStore는 자연어를 Vector로 embedding한 후, 이를 저장하는 공간입니다.  \n",
        "쿼리나 문서 등의 Emabedding이 저장된 후, 재사용 및 참조를 위해 VectorStroe에서 빠르게 유사도를 측정, 탐색할 수 있습니다.  \n",
        "VectorStore로는 Chroma나 Faiss를 가장 많이 사용합니다.  \n",
        "  \n",
        "예제로는, 가장 간단한 chromadb를 사용해보겠습니다.  "
      ],
      "metadata": {
        "id": "6WQFYzDRElUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install chromadb"
      ],
      "metadata": {
        "id": "bUP9BzkqoaFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Chroma"
      ],
      "metadata": {
        "id": "CNoueLanSnrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "제일 처음에 사용했던, PDF를 다시 사용하도록 합니다!  "
      ],
      "metadata": {
        "id": "ItLO4FouzYUF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 위에서 사용했던 코드입니다\n",
        "loader = PyPDFLoader(\"/content/Demian.pdf\")\n",
        "pages = loader.load_and_split()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0, length_function = tiktoken_len)\n",
        "docs = text_splitter.split_documents(pages)"
      ],
      "metadata": {
        "id": "U2kUZ-B-zLZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chroma에 임베딩 시킵니다  "
      ],
      "metadata": {
        "id": "x7Iwc1EbR-zM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "db = Chroma.from_documents(docs, embedding_model)"
      ],
      "metadata": {
        "id": "FprgEvy01jtK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 쿼리를 날려보겠습니다"
      ],
      "metadata": {
        "id": "lUM3Mf_5UIFj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"how Demian look like?\"\n",
        "docs = db.similarity_search(query)"
      ],
      "metadata": {
        "id": "CmsGfP3oT6C0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(docs[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tz2MJlMCUToL",
        "outputId": "c7da5713-4af8-4322-dc81-a44348d69063"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEMIAN \n",
            "Why had it only just dawned on me I It wu Demian'• \n",
            "face. \n",
            "Later I often comP9Xed the face on the paper with \n",
            "Demian's features as l remembered them. They were \n",
            "certainly, though similar, not the same. But beyond all \n",
            "doubt, it was Demian. \n",
            "Once one evening in early summer the sun was slant­\n",
            "ing red through my window that faced westward. Inside \n",
            "the room it was dusk It occurred to me to attach the \n",
            "picture of Beatrice (or Demian) to the window bar and \n",
            "watch the effect as the sun shone through. The outlines \n",
            "of the face were blurred but the eyes, edged with pink., \n",
            "the brightness of the forehead and the energetic red \n",
            "mouth glowed excitingly from the surface. For a long \n",
            "time I sat opposite it even after the picture had faded \n",
            "out. And gradually a feeling came over me that it was \n",
            "neither Beatrice nor Demian but myself. Not that the \n",
            "picture was like me-I did not feel it should be-but \n",
            "the face somehow expressed my life, it was my inner self, \n",
            "my fate or my daimon. That was how my friend would \n",
            "look if and when I ever found him again. The woman I \n",
            "loved, if ever I had a lover, would look like that. It was \n",
            "the pattern of my life and death; it expressed the tone \n",
            "and rhythm of my fate. \n",
            "During those weeks I had embarked on some reading \n",
            "which made a deeper impression on me than anything I \n",
            "had read before. Even in later life I have seldom been \n",
            "so completely absorbed by any books, perhaps not even \n",
            "excepting Nietzsche's. It was a volume of Novalis• con-\n",
            "• T,anslalor, not.. The novel D,mian was fint publiahed under the \n",
            "paeuc:IO!lym Emil Sinclair, the name or a friend or the poet Novalil \n",
            "whom Hme 10 much admired, · \n",
            "91 \n",
            "Downloaded from https://www.holybooks.com\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Face, features, looks like 등 데미안의 생김새를 담고 있는 페이지가 출력되었습니다  \n",
        "굉장히 빠른 속도로 검색했습니다!  "
      ],
      "metadata": {
        "id": "iXpn-xGtUgJ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step5 : Retriever 사용해보기  \n",
        "\n",
        "Retriever는 사용자 입력 시 임베딩 모델을 거친 쿼리와 vectorstore에 저장된 사전 정보들 간의 유사 문장을 찾아내어 출력하는 역할을 합니다.  \n",
        "  \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Av2jNoHjElXI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n"
      ],
      "metadata": {
        "id": "XQ8suJ1c-hGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "긴 문서에서 원하는 답변을 찾을 수 있는 RetrieverQA 체인을 사용합니다  "
      ],
      "metadata": {
        "id": "S40ekPtTWirT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
        "\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model = \"gemini-pro\", temperature=0.0)"
      ],
      "metadata": {
        "id": "z7u1YK_6Ou3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "체인의 종류, 탐색 방법과 그에 따른 파라메터를 설정해줍니다  "
      ],
      "metadata": {
        "id": "PlioWGPtW8vM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qa = RetrievalQA.from_chain_type(llm, chain_type=\"stuff\",\n",
        "                                 retriever=db.as_retriever(\n",
        "                                     search_type=\"mmr\",\n",
        "                                     search_kwargs={\"k\": 3, \"fetch_k\" : 10}),\n",
        "                                 return_source_documents=True)"
      ],
      "metadata": {
        "id": "0Ma1qqWwNXen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"how demian looks like\"\n",
        "result = qa(query)"
      ],
      "metadata": {
        "id": "2d8WxRgoNmRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "마크다운 형식으로 출력해봅니다"
      ],
      "metadata": {
        "id": "pLZr3whnXTNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown, display\n",
        "display(Markdown(result[\"result\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "ORBaSJU0Plsz",
        "outputId": "6b0ea754-0d9d-474a-8f0e-00800baca047"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Physical Appearance:**\n\n* **Age:** 15-16 years old\n* **Height:** Average\n* **Build:** Slender and athletic\n* **Hair:** Dark brown, short and neatly combed\n* **Eyes:** Deep blue, piercing and intelligent\n* **Facial Features:** Sharp and angular, with a strong jawline and high cheekbones\n* **Skin:** Fair and smooth\n\n**Clothing:**\n\n* **School Uniform:** Black blazer, white shirt, gray trousers, and a black tie\n* **Casual Wear:** Jeans, T-shirts, hoodies, and sneakers\n\n**Other Notable Features:**\n\n* **Scar:** A small scar on his left cheekbone, a reminder of a childhood accident\n* **Expression:** Often serious and contemplative, but can also be mischievous and playful\n* **Demeanor:** Intelligent, introspective, and independent\n* **Aura:** Mysterious and enigmatic, with a hint of danger"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RAG를 사용하지 않은 llm 호출도 시도해보세요!"
      ],
      "metadata": {
        "id": "VFZgpq6vXigB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#llm2 = ChatGoogleGenerativeAI(model = \"gemini-pro\", temperature=0.0)\n",
        "#request = llm2.invoke(\"how demian looks like\")\n",
        "#display(Markdown(request.content))\n"
      ],
      "metadata": {
        "id": "304uRfwYR2Zz"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "수고하셨습니다!"
      ],
      "metadata": {
        "id": "owSPP-WtXrZl"
      }
    }
  ]
}